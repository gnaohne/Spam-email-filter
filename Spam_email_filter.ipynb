{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OK-eISjRRkbs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dfs-02PRpkd"
      },
      "source": [
        "# **Read data process**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUDVe6koRkbu",
        "outputId": "c5dd507e-6b84-4623-877d-1196521a10e9"
      },
      "outputs": [],
      "source": [
        "# Read data from train.csv\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# Display 5 first rows of the dataframe\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR5SjLDnRkbv",
        "outputId": "05f8adc1-cc5d-4b24-ddd9-09e6676ea670"
      },
      "outputs": [],
      "source": [
        "# Read data from val.csv\n",
        "val_data = pd.read_csv('val.csv')\n",
        "\n",
        "# Display 5 first rows of the dataframe\n",
        "val_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB7JkaygRkbv"
      },
      "outputs": [],
      "source": [
        "# Pre-process the data\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pBGbUjeRkbw"
      },
      "outputs": [],
      "source": [
        "def clean_message(m):\n",
        "    m = re.sub(r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$','',str(m)) # email addresses\n",
        "    m = re.sub(r'(http|https|ftp)://[a-zA-Z0-9\\\\./]+', ' ', str(m)) # URLs\n",
        "    m = re.sub(r'\\d+', ' ', str(m)) # number\n",
        "    m = re.sub(r'[^a-zA-Z]', ' ', str(m)) # non alphabet\n",
        "    m = m.translate(str.maketrans('', '', punctuation)) # punctuation\n",
        "    m = re.sub(r'\\s+', ' ', str(m)) # remove multiple spaces\n",
        "    m = m.lower() # lower case\n",
        "    return m\n",
        "\n",
        "def clean_column(data, col_name):\n",
        "    # remove email addresses, URLs, numbers, non-alphabets, punctuations, multiple spaces, and lower case\n",
        "    data[col_name] = data[col_name].apply(clean_message)\n",
        "\n",
        "    # remove stopwords\n",
        "    data[col_name]= data[col_name].apply(lambda x: ' '.join([item for item in x.split() if item not in stopwords]))\n",
        "\n",
        "    # remove words with length less than 3 and more than 15 characters to remove noise\n",
        "    data[col_name]= data[col_name].apply(lambda x: ' '.join([item for item in x.split() if 3 <= len(item) <= 15]))\n",
        "\n",
        "    # lemmatization\n",
        "    lem = WordNetLemmatizer()\n",
        "\n",
        "    # lemmatize the words into verb form\n",
        "    data[col_name] = data[col_name].apply(lambda x: ' '.join([lem.lemmatize(word,pos='v') for word in x.split()]))\n",
        "    # lemmatize the words into noun form\n",
        "    data[col_name] = data[col_name].apply(lambda x: ' '.join([lem.lemmatize(word,pos='n') for word in x.split()]))\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubk3zhNKRkbw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
